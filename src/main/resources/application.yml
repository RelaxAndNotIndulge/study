spring:
  cloud:
    stream:
      function:
        definition: process
      default-binder: kafka
      kafka:
        binder:
          brokers:
            - 192.168.10.142:9092
          auto-add-partitions: true #自动增加分区数

      bindings:
        # 接收消息
        process-in-0:
          destination: logTopic2 #消息发往的目的地，对应topic
          content-type: application/json # 默认application/json，还可以配置成text/plan  #消息发送的格式，接收端不用指定格式，但是发送端要
          group: dev-log-input-group

#        # 发送消息
#        myOutput:
#          #消息发往的目的地
#          destination: stream-demo
#          #消息发送的格式，接收端不用指定格式，但是发送端要
#          content-type: text/plain
#          producer:
#            #分区的主键，根据什么来分区，下面的payload.id只是一个对象的id用于做为Key，用来说明的。希望不要误解
#            partitionKeyExpression: payload.id
#            #Key和分区数量进行取模去分配消息，这里分区数量配置为2
#            partitionCount: 2